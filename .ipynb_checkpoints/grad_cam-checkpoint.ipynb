{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from torch.utils.data.sampler import  WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "import pdb\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"7\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_path = \"/data3/zyh_data/zyh_hcc_model/ours_final11/\"\n",
    "model_list = []\n",
    "for root,dirs,files in os.walk(total_path):\n",
    "    for file in files:\n",
    "        model_list.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['/data3/zyh_data/zyh_hcc_model/ours_final11/0/ours_2749_hbp035_fold0_0.782%.t7',\n",
    "             '/data3/zyh_data/zyh_hcc_model/ours_final11/1/ours_2749_hbp001_fold1_0.781%.t7',\n",
    "             '/data3/zyh_data/zyh_hcc_model/ours_final11/2/ours_2749_hbp001_fold2_0.712%.t7',\n",
    "             '/data3/zyh_data/zyh_hcc_model/ours_final11/3/ours_7214_hbp040_fold3_0.733%.t7',\n",
    "             '/data3/zyh_data/zyh_hcc_model/ours_final11/4/ours_3885_hbp001_fold4_0.719%.t7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data3/lh/hcc'\n",
    "label_dir = \"./label/\"\n",
    "sequence = ['hbp','pre']\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "/data3/lh/hcc/hbp/*hbp.npy 524\n",
      "load valid 54\n",
      "[26, 18, 10]\n",
      "56\n",
      "/data3/lh/hcc/hbp/*hbp.npy 524\n",
      "load valid 53\n",
      "[25, 18, 10]\n",
      "55\n",
      "/data3/lh/hcc/hbp/*hbp.npy 524\n",
      "load valid 55\n",
      "[26, 19, 10]\n",
      "55\n",
      "/data3/lh/hcc/hbp/*hbp.npy 524\n",
      "load valid 53\n",
      "[26, 18, 9]\n",
      "55\n",
      "/data3/lh/hcc/hbp/*hbp.npy 524\n",
      "load valid 54\n",
      "[25, 19, 10]\n"
     ]
    }
   ],
   "source": [
    "# load all dataset\n",
    "valid_set = [hcc_3d_all_nnnm(data_dir, label_dir, usage = 'valid', valid_fold = l, sequ_name = sequence, return_cfeature = True) for l in range(5)]\n",
    "valid_loader_list = [torch.utils.data.DataLoader(l, batch_size=batch_size, shuffle = False, pin_memory=True, num_workers=4) for l in valid_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b16_config():\n",
    "    \"\"\"Returns the ViT-B/16 configuration.\"\"\"\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.hidden_size = 512\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 512*4\n",
    "    config.transformer.num_heads = 4\n",
    "    config.transformer.num_layers = 1\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(n_classes, pred, target):\n",
    "    confusion_matrix = np.zeros((n_classes, n_classes))\n",
    "    for p, ta in zip(pred, target):\n",
    "        confusion_matrix[int(p),int(ta)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b16_config():\n",
    "    \"\"\"Returns the ViT-B/16 configuration.\"\"\"\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.hidden_size = 512\n",
    "    config.transformer = ml_collections.ConfigDict()\n",
    "    config.transformer.mlp_dim = 512*4\n",
    "    config.transformer.num_heads = 4\n",
    "    config.transformer.num_layers = 1\n",
    "    config.transformer.attention_dropout_rate = 0.0\n",
    "    config.transformer.dropout_rate = 0.1\n",
    "    config.classifier = 'token'\n",
    "    config.representation_size = None\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(model_path, valid_loader, modal = \"pre\", split = 0, label = 0):\n",
    "    student = concat_studentNet_lh(num_classes=3,num_sequ=1,config=get_b16_config()).to(device)\n",
    "    student_checkpoint = torch.load(model_path)\n",
    "    student=student_checkpoint[\"model\"]\n",
    "    # 0\n",
    "    if split == 0:\n",
    "        if modal == \"pre\":\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_0\", save_maps=True,layer='pre_model.base_model.down_tr64.ops')\n",
    "        else:\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_0\", save_maps=True,layer='hbp_model.base_model.down_tr64.ops')\n",
    "    \n",
    "    # 1\n",
    "    elif split == 1:\n",
    "        if modal == \"pre\":\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_1\", save_maps=True,layer='pre_model.base_model.down_tr64.ops')\n",
    "        else:\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_1\", save_maps=True,layer='hbp_model.base_model.down_tr64.ops')\n",
    "    # 2\n",
    "    elif split == 2:\n",
    "        if modal == \"pre\":\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_2\", save_maps=True,layer='pre_model.base_model.down_tr64.ops')\n",
    "        else:\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_2\", save_maps=True,layer='hbp_model.base_model.down_tr64.ops')    \n",
    "    # 3\n",
    "    elif split == 3:\n",
    "        if modal == \"pre\":\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_3\", save_maps=True,layer='pre_model.base_model.down_tr64.ops')\n",
    "        else:\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_3\", save_maps=True,layer='hbp_model.base_model.down_tr64.ops')    \n",
    "    # 4\n",
    "    elif split == 4:\n",
    "        if modal == \"pre\":\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_4\", save_maps=True,layer='pre_model.base_model.down_tr64.ops')\n",
    "        else:\n",
    "            student = medcam.inject(student,label=label, output_dir = \"attention_map_4\", save_maps=True,layer='hbp_model.base_model.down_tr64.ops')    \n",
    "    \n",
    "    student.eval()\n",
    "    \n",
    "    \n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    TARGETS_OH = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target, mask,_,_,_) in enumerate(valid_loader):\n",
    "#             print(idx, end = '\\r')\n",
    "            data, target = data.to(device), target.float().to(device)\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "            hbp = data[:,0:1,:,:,:]\n",
    "            pre = data[:,1:2,:,:,:]\n",
    "\n",
    "            hbp_mask = mask[:,0:1,:,:,:]\n",
    "            pre_mask = mask[:,1:2,:,:,:]\n",
    "\n",
    "            #logits,student_cls_token,student_pre,student_hbp = student(hbp,pre,hbp_mask,pre_mask) \n",
    "            logits = student(data).cpu()\n",
    "    \n",
    "            pred = logits.sigmoid().max(1)[1]\n",
    "            LOGITS.append(logits)\n",
    "            PREDS.append(pred)\n",
    "            \n",
    "            TARGETS.append(target.max(1)[1].cpu())\n",
    "            TARGETS_OH.append(target.cpu())\n",
    "            \n",
    "    LOGITS = torch.cat(LOGITS).detach()\n",
    "    LOGITS2 = F.softmax(LOGITS, 1).numpy()\n",
    "    PREDS = torch.cat(PREDS).numpy()\n",
    "    TARGETS = torch.cat(TARGETS).numpy()\n",
    "    TARGETS_OH = torch.cat(TARGETS_OH).numpy()\n",
    "    \n",
    "    auc_case = roc_auc_score(np.round(np.array(TARGETS_OH), 0), np.array(LOGITS2), average = \"macro\", multi_class = \"ovo\")\n",
    "    print(\"The auc\", auc_case)\n",
    "    acc = (PREDS == TARGETS).mean() * 100.\n",
    "    # get best acc\n",
    "    maxacc=acc\n",
    "    bestpred = PREDS\n",
    "    for i in range(1,99):\n",
    "        for j in range(1,99):\n",
    "            thre1 = i*0.01\n",
    "            thre2 = j*0.01\n",
    "            \n",
    "            predn = np.zeros_like(PREDS)\n",
    "            \n",
    "            for k in range(1,LOGITS2.shape[0]):\n",
    "                if LOGITS2[k,2] > thre1:\n",
    "                    predn[k] = 2\n",
    "                elif LOGITS2[k,1] > thre2:\n",
    "                    predn[k] = 1\n",
    "            cacc = (predn == TARGETS).mean() * 100\n",
    "            #print(cacc)\n",
    "            if cacc > maxacc:\n",
    "                bestpred = predn\n",
    "                maxacc = cacc\n",
    "#                 print(maxacc)\n",
    "                \n",
    "    get_confusion_matrix(3, bestpred, TARGETS)\n",
    "    m_dirt = metrics.classification_report(TARGETS,bestpred, output_dict=True)\n",
    "#     print(m_dirt['weighted avg'])\n",
    "#     print(m_dirt['accuracy'])\n",
    "#     print(m_dirt)\n",
    "    return auc_case, m_dirt['accuracy'], m_dirt['weighted avg']['precision'], m_dirt['weighted avg']['recall'], m_dirt['weighted avg']['f1-score']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img_path = \"/data3/zyh_data/heatmap_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc 0.781778612334168\n",
      "The auc 0.781778612334168\n",
      "The auc 0.781386735572782\n",
      "The auc 0.781386735572782\n",
      "The auc 0.7119111586806687\n",
      "The auc 0.7119111586806687\n",
      "The auc 0.7328221161554495\n",
      "The auc 0.7328221161554495\n",
      "The auc 0.719274047186933\n",
      "The auc 0.719274047186933\n"
     ]
    }
   ],
   "source": [
    "zhibiao0_list = []\n",
    "zhibiao1_list = []\n",
    "zhibiao2_list = []\n",
    "zhibiao3_list = []\n",
    "zhibiao4_list = []\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    if model_list[i].split('/')[5] == '0':\n",
    "        zhibiao0_list.append(get_metric(model_list[i],valid_loader_list[0], \"pre\",split=0))\n",
    "        zhibiao0_list.append(get_metric(model_list[i],valid_loader_list[0], \"hbp\",split=0))\n",
    "    if model_list[i].split('/')[5] == '1':\n",
    "        zhibiao1_list.append(get_metric(model_list[i],valid_loader_list[1], \"pre\",split=1))\n",
    "        zhibiao1_list.append(get_metric(model_list[i],valid_loader_list[1], \"hbp\",split=1))\n",
    "    if model_list[i].split('/')[5] == '2':\n",
    "        zhibiao2_list.append(get_metric(model_list[i],valid_loader_list[2], \"pre\",split=2))\n",
    "        zhibiao2_list.append(get_metric(model_list[i],valid_loader_list[2], \"hbp\",split=2))\n",
    "    if model_list[i].split('/')[5] == '3':\n",
    "        zhibiao3_list.append(get_metric(model_list[i],valid_loader_list[3], \"pre\",split=3))\n",
    "        zhibiao3_list.append(get_metric(model_list[i],valid_loader_list[3], \"hbp\",split=3))\n",
    "    if model_list[i].split('/')[5] == '4':\n",
    "        zhibiao4_list.append(get_metric(model_list[i],valid_loader_list[4], \"pre\",split=4))\n",
    "        zhibiao4_list.append(get_metric(model_list[i],valid_loader_list[4], \"hbp\",split=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取label和预测label的txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_pred(model_path, valid_loader, modal = \"pre\", split = 0, label = 0):\n",
    "    \n",
    "    student = concat_studentNet_lh(num_classes=3,num_sequ=1,config=get_b16_config()).to(device)\n",
    "    student_checkpoint = torch.load(model_path)\n",
    "    student=student_checkpoint[\"model\"]\n",
    "    student.eval()\n",
    "    \n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    TARGETS_OH = []\n",
    "    IDNAME = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target, mask,_,_,_) in enumerate(valid_loader):\n",
    "            \n",
    "            b = data.shape[0]\n",
    "            idname_list = []\n",
    "            for ii in range(b):\n",
    "                idname = valid_loader.dataset.name[ii]\n",
    "                idname_list.append(idname)\n",
    "            IDNAME.extend(idname_list)\n",
    "#             print(idx, end = '\\r')\n",
    "            data, target = data.to(device), target.float().to(device)\n",
    "            logits = student(data).cpu()\n",
    "    \n",
    "            pred = logits.sigmoid().max(1)[1]\n",
    "            LOGITS.append(logits)\n",
    "            PREDS.append(pred)\n",
    "            \n",
    "            TARGETS.append(target.max(1)[1].cpu())\n",
    "            TARGETS_OH.append(target.cpu())\n",
    "    \n",
    "    \n",
    "    LOGITS = torch.cat(LOGITS).detach()\n",
    "    LOGITS2 = F.softmax(LOGITS, 1).numpy()\n",
    "    PREDS = torch.cat(PREDS).numpy()\n",
    "    TARGETS = torch.cat(TARGETS).numpy()\n",
    "    TARGETS_OH = torch.cat(TARGETS_OH).numpy()\n",
    "    \n",
    "    auc_case = roc_auc_score(np.round(np.array(TARGETS_OH), 0), np.array(LOGITS2), average = \"macro\", multi_class = \"ovo\")\n",
    "    print(\"The auc\", auc_case)\n",
    "    acc = (PREDS == TARGETS).mean() * 100.\n",
    "    # get best acc\n",
    "    maxacc=acc\n",
    "    bestpred = PREDS\n",
    "    for i in range(1,99):\n",
    "        for j in range(1,99):\n",
    "            thre1 = i*0.01\n",
    "            thre2 = j*0.01\n",
    "            \n",
    "            predn = np.zeros_like(PREDS)\n",
    "            \n",
    "            for k in range(1,LOGITS2.shape[0]):\n",
    "                if LOGITS2[k,2] > thre1:\n",
    "                    predn[k] = 2\n",
    "                elif LOGITS2[k,1] > thre2:\n",
    "                    predn[k] = 1\n",
    "            cacc = (predn == TARGETS).mean() * 100\n",
    "            #print(cacc)\n",
    "            if cacc > maxacc:\n",
    "                bestpred = predn\n",
    "                maxacc = cacc\n",
    "#                 print(maxacc)\n",
    "                \n",
    "    \n",
    "#     print(m_dirt['weighted avg'])\n",
    "#     print(m_dirt['accuracy'])\n",
    "#     print(m_dirt)\n",
    "    return IDNAME,bestpred,TARGETS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc 0.781778612334168\n",
      "The auc 0.781386735572782\n",
      "The auc 0.7119111586806687\n",
      "The auc 0.7328221161554495\n",
      "The auc 0.719274047186933\n"
     ]
    }
   ],
   "source": [
    "zhibiao0_list = []\n",
    "zhibiao1_list = []\n",
    "zhibiao2_list = []\n",
    "zhibiao3_list = []\n",
    "zhibiao4_list = []\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    if model_list[i].split('/')[5] == '0':\n",
    "        zhibiao0_list.append(get_label_pred(model_list[i],valid_loader_list[0], \"pre\",split=0))\n",
    "    if model_list[i].split('/')[5] == '1':\n",
    "        zhibiao1_list.append(get_label_pred(model_list[i],valid_loader_list[1], \"pre\",split=1))\n",
    "    if model_list[i].split('/')[5] == '2':\n",
    "        zhibiao2_list.append(get_label_pred(model_list[i],valid_loader_list[2], \"pre\",split=2))\n",
    "    if model_list[i].split('/')[5] == '3':\n",
    "        zhibiao3_list.append(get_label_pred(model_list[i],valid_loader_list[3], \"pre\",split=3))\n",
    "    if model_list[i].split('/')[5] == '4':\n",
    "        zhibiao4_list.append(get_label_pred(model_list[i],valid_loader_list[4], \"pre\",split=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 2, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 2, 2, 0, 0, 0, 1, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 0, 0,\n",
       "       1, 0, 1, 0, 2, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhibiao0_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lh/hcc_kd/pred_label.txt\",\"a\") as fw:\n",
    "    tmp0_name = zhibiao0_list[0][0] # idname\n",
    "    tmp0_pred = zhibiao0_list[0][1] # pred\n",
    "    tmp0_label = zhibiao0_list[0][2] # label\n",
    "    for i in range(len(tmp0_name)):\n",
    "        fw.write(tmp0_name[i] + '\\t' + str(tmp0_pred[i]) + '\\t' + str(tmp0_label[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lh/hcc_kd/pred_label.txt\",\"a\") as fw:\n",
    "    tmp1_name = zhibiao1_list[0][0] # idname\n",
    "    tmp1_pred = zhibiao1_list[0][1] # pred\n",
    "    tmp1_label = zhibiao1_list[0][2] # label\n",
    "    for i in range(len(tmp1_name)):\n",
    "        fw.write(tmp1_name[i] + '\\t' + str(tmp1_pred[i]) + '\\t' + str(tmp1_label[i]) + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lh/hcc_kd/pred_label.txt\",\"a\") as fw:\n",
    "    tmp2_name = zhibiao2_list[0][0] # idname\n",
    "    tmp2_pred = zhibiao2_list[0][1] # pred\n",
    "    tmp2_label = zhibiao2_list[0][2] # label\n",
    "    for i in range(len(tmp2_name)):\n",
    "        fw.write(tmp2_name[i] + '\\t' + str(tmp2_pred[i]) + '\\t' + str(tmp2_label[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lh/hcc_kd/pred_label.txt\",\"a\") as fw:    \n",
    "    tmp3_name = zhibiao3_list[0][0] # idname\n",
    "    tmp3_pred = zhibiao3_list[0][1] # pred\n",
    "    tmp3_label = zhibiao3_list[0][2] # label\n",
    "    for i in range(len(tmp3_name)):\n",
    "        fw.write(tmp3_name[i] + '\\t' + str(tmp3_pred[i]) + '\\t' + str(tmp3_label[i]) + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lh/hcc_kd/pred_label.txt\",\"a\") as fw:\n",
    "    tmp4_name = zhibiao4_list[0][0] # idname\n",
    "    tmp4_pred = zhibiao4_list[0][1] # pred\n",
    "    tmp4_label = zhibiao4_list[0][2] # label\n",
    "    for i in range(len(tmp4_name)):\n",
    "        fw.write(tmp4_name[i] + '\\t' + str(tmp4_pred[i]) + '\\t' + str(tmp4_label[i]) + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def cplt(cfold, label = 1, modality=\"pre\"):\n",
    "    idname = valid_loader_list[cfold].dataset.name\n",
    "    for idx, (data, target, mask,_,_,_) in enumerate(valid_loader_list[cfold]):\n",
    "        b = data.shape[0]\n",
    "        for i in range(b):\n",
    "            if target[i,label] != 0.933:\n",
    "                continue\n",
    "\n",
    "            # 原图的保存\n",
    "            # 先运行原图的，要注释后面热力图的生成。\n",
    "            # 运行热力图的时候 ，再把原图的生成注释掉\n",
    "#             if modality == \"pre\":\n",
    "#                 img = data[i,1,:,:,:].numpy()\n",
    "#             elif modality == \"hbp\":\n",
    "#                 img = data[i,0,:,:,:].numpy()\n",
    "\n",
    "#             slice_t = img.shape[2] \n",
    "#             for j in range(slice_t):\n",
    "#                 plt.axis('on') # 关掉坐标轴为 off\n",
    "#                 plt.imshow(img[:,:,j], cmap=\"gray\")\n",
    "#                 mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "#                             str(valid_loader_list[cfold].dataset.name[i]) + \"_image_\" + \n",
    "#                             str(j) + \".png\",img[:,:,j],cmap=\"gray\")\n",
    "\n",
    "#             for pre\n",
    "            if cfold == 0:\n",
    "                if modality == \"pre\":\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_0/pre_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "        #             print(\"scan.shape\",scan.shape) # (64,16,64)\n",
    "                    slice_pre = scan.shape[1]\n",
    "                    for j in range(slice_pre):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                    #     print(norm_img.sum())\n",
    "                    #     print(gray_img)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                    #     print(norm_img8.shape)\n",
    "                        #heat_img = cv2.cvtColor(norm_img8, cv2.COLOR_GRAY2BGR)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "                elif modality == \"hbp\":\n",
    "                    ## for hbp\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_0/hbp_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    #                 print(\"scan.shape\",scan.shape)\n",
    "                    slice_hbp = scan.shape[1]\n",
    "                    for j in range(slice_hbp):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "            elif cfold == 1:\n",
    "                if modality == \"pre\":\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_1/pre_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "        #             print(\"scan.shape\",scan.shape) # (64,16,64)\n",
    "                    slice_pre = scan.shape[1]\n",
    "                    for j in range(slice_pre):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                    #     print(norm_img.sum())\n",
    "                    #     print(gray_img)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                    #     print(norm_img8.shape)\n",
    "                        #heat_img = cv2.cvtColor(norm_img8, cv2.COLOR_GRAY2BGR)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "                elif modality == \"hbp\":\n",
    "                    ## for hbp\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_1/hbp_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    #                 print(\"scan.shape\",scan.shape)\n",
    "                    slice_hbp = scan.shape[1]\n",
    "                    for j in range(slice_hbp):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img)\n",
    "            elif cfold == 2:\n",
    "                if modality == \"pre\":\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_2/pre_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "        #             print(\"scan.shape\",scan.shape) # (64,16,64)\n",
    "                    slice_pre = scan.shape[1]\n",
    "                    for j in range(slice_pre):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                    #     print(norm_img.sum())\n",
    "                    #     print(gray_img)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                    #     print(norm_img8.shape)\n",
    "                        #heat_img = cv2.cvtColor(norm_img8, cv2.COLOR_GRAY2BGR)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "                elif modality == \"hbp\":\n",
    "                    ## for hbp\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_2/hbp_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    #                 print(\"scan.shape\",scan.shape)\n",
    "                    slice_hbp = scan.shape[1]\n",
    "                    for j in range(slice_hbp):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "            elif cfold == 3:\n",
    "                if modality == \"pre\":\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_3/pre_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "        #             print(\"scan.shape\",scan.shape) # (64,16,64)\n",
    "                    slice_pre = scan.shape[1]\n",
    "                    for j in range(slice_pre):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                    #     print(norm_img.sum())\n",
    "                    #     print(gray_img)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                    #     print(norm_img8.shape)\n",
    "                        #heat_img = cv2.cvtColor(norm_img8, cv2.COLOR_GRAY2BGR)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "                elif modality == \"hbp\":\n",
    "                    ## for hbp\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_3/hbp_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    #                 print(\"scan.shape\",scan.shape)\n",
    "                    slice_hbp = scan.shape[1]\n",
    "                    for j in range(slice_hbp):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "            elif cfold == 4:\n",
    "                if modality == \"pre\":\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_4/pre_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "        #             print(\"scan.shape\",scan.shape) # (64,16,64)\n",
    "                    slice_pre = scan.shape[1]\n",
    "                    for j in range(slice_pre):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                    #     print(norm_img.sum())\n",
    "                    #     print(gray_img)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                    #     print(norm_img8.shape)\n",
    "                        #heat_img = cv2.cvtColor(norm_img8, cv2.COLOR_GRAY2BGR)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) \n",
    "                elif modality == \"hbp\":\n",
    "                    ## for hbp\n",
    "                    heatmap_path = \"/home/lh/hcc_kd/hcc_kd_dml2.0_new_ours_copy/attention_map_4/hbp_model.base_model.down_tr64.ops/\"\n",
    "                    c_path = os.path.join(heatmap_path, \"attention_map_\"+str(idx)+\"_\" + str(i) + \"_0.nii.gz\")\n",
    "                    itkimage = sitk.ReadImage(c_path)\n",
    "                    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    #                 print(\"scan.shape\",scan.shape)\n",
    "                    slice_hbp = scan.shape[1]\n",
    "                    for j in range(slice_hbp):\n",
    "                        theat = scan[:,j,:]\n",
    "                        gray_img = theat\n",
    "                        norm_img = np.zeros(gray_img.shape)\n",
    "                        cv2.normalize(gray_img , norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "                        norm_img8 = gray_img.astype(np.uint8)\n",
    "                        heat_img = cv2.applyColorMap(norm_img8, cv2.COLORMAP_JET) # 注意此处的三通道热力图是cv2专有的GBR排列\n",
    "                        heat_img = cv2.cvtColor(heat_img, cv2.COLOR_BGR2RGB)# 将BGR图像转为RGB图像\n",
    "\n",
    "                        mpimg.imsave(save_img_path + \"/\" + modality + \"/\" + str(label) + \"/\" +  \n",
    "                                    str(valid_loader_list[cfold].dataset.name[i]) + \"_heatmap_\" + \n",
    "                                    str(j) + \".png\",heat_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_list)):\n",
    "    if model_list[i].split('/')[5] == '0':\n",
    "        cplt(0, label = 0, modality=\"pre\") # label为2的热力图\n",
    "        cplt(0, label = 0, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(0, label = 1, modality=\"pre\") # label为2的热力图\n",
    "        cplt(0, label = 1, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(0, label = 2, modality=\"pre\") # label为2的热力图\n",
    "        cplt(0, label = 2, modality=\"hbp\") # label为2的热力图\n",
    "        \n",
    "    if model_list[i].split('/')[5] == '1':\n",
    "        cplt(1, label = 0, modality=\"pre\") # label为2的热力图\n",
    "        cplt(1, label = 0, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(1, label = 1, modality=\"pre\") # label为2的热力图\n",
    "        cplt(1, label = 1, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(1, label = 2, modality=\"pre\") # label为2的热力图\n",
    "        cplt(1, label = 2, modality=\"hbp\") # label为2的热力图\n",
    "    if model_list[i].split('/')[5] == '2':\n",
    "        cplt(2, label = 0, modality=\"pre\") # label为2的热力图\n",
    "        cplt(2, label = 0, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(2, label = 1, modality=\"pre\") # label为2的热力图\n",
    "        cplt(2, label = 1, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(2, label = 2, modality=\"pre\") # label为2的热力图\n",
    "        cplt(2, label = 2, modality=\"hbp\") # label为2的热力图\n",
    "    if model_list[i].split('/')[5] == '3':\n",
    "        cplt(3, label = 0, modality=\"pre\") # label为2的热力图\n",
    "        cplt(3, label = 0, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(3, label = 1, modality=\"pre\") # label为2的热力图\n",
    "        cplt(3, label = 1, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(3, label = 2, modality=\"pre\") # label为2的热力图\n",
    "        cplt(3, label = 2, modality=\"hbp\") # label为2的热力图\n",
    "    if model_list[i].split('/')[5] == '4':\n",
    "        cplt(4, label = 0, modality=\"pre\") # label为2的热力图\n",
    "        cplt(4, label = 0, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(4, label = 1, modality=\"pre\") # label为2的热力图\n",
    "        cplt(4, label = 1, modality=\"hbp\") # label为2的热力图\n",
    "        cplt(4, label = 2, modality=\"pre\") # label为2的热力图\n",
    "        cplt(4, label = 2, modality=\"hbp\") # label为2的热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
